from snakemake.shell import shell


shell.executable("bash")

import pandas as pd

samples = "1 2 3".split()
cells = "fibroblast keratinocyte melanocyte".split()


prefix = config["prefix"]

sample_sheet = pd.read_table(config["sample_sheet"], sep=" ")
ss = sample_sheet

wildcard_constraints:
    cell = "({})".format("|".join(ss.Group.drop_duplicates()))


rule all:
    input:
        f"{prefix}/data/epic-cluster/epic/matrixes.gz",
        expand("{prefix}/data/epic-merge/{caller}/matrixes.gz",
               prefix = prefix,
               cell=cells,
               caller="epic".split()), # macs2
        f"{prefix}/data/epic-merge/test/matrixes.gz",
        f"{prefix}/data/epic/chip_bw/all.bw",
        f"{prefix}/data/epic/input_bw/all.bw"


def get_files(w, chip):

    celltype = w.cell

    files = list(ss.loc[(ss.ChIP == chip) & (ss.Group == celltype)].Path)

    return files


def get_all_files(chip):

    files = list(ss.loc[ss.ChIP == chip].Path)

    return files


rule run_epic:
    input:
        chip = lambda w: get_files(w, "ChIP"),
        input = lambda w: get_files(w, "Input"),
    output:
        csv = "{prefix}/data/epic/{cell}.csv",
        bed = "{prefix}/data/epic/{cell}.bed",
        matrix = "{prefix}/data/epic/{cell}.matrix.gz",
        log2_fc_bigwig = "{prefix}/data/epic/log2_fc_{cell}.bw",
        input_bigwig = "{prefix}/data/epic/input_bw/{cell}.bw",
        chip_bigwig = "{prefix}/data/epic/chip_bw/{cell}.bw"
    params:
        individual_bigwig = "{prefix}/data/epic/bw/",
        individual_log2_fc_bigwig = "{prefix}/data/epic/i2bw/"
    threads:
        48
    shell:
        "epic -cpu {threads} -g 3 -w "
        "200 -gn hg19 " # -fs 200 "
        "-fs 200 "
        "-b {output.bed} -t {input.chip} -c {input.input} "
        "-sm {output.matrix} "
        " --bigwig {params.individual_bigwig} "
        " -i2bw {params.individual_log2_fc_bigwig} "
        " --log2fc-bigwig {output.log2_fc_bigwig} "
        " --input-bigwig {output.input_bigwig} "
        " --chip-bigwig {output.chip_bigwig} "
        "> {output.csv}"


rule create_chip_input_sum:
    input:
        chip = get_all_files("ChIP"),
        input = get_all_files("Input")
    output:
        sum_chip = "{prefix}/data/epic/chip_bw/all.bw",
        sum_input = "{prefix}/data/epic/input_bw/all.bw"
    threads:
        48
    shell:
        "epic -cpu {threads} -g 3 -w "
        "200 -gn hg19 "
        "-fs 200 "
        "-t {input.chip} -c {input.input} "
        " --input-bigwig {output.sum_input} "
        " --chip-bigwig {output.sum_chip} "
        "> /dev/null"


rule run_macs2:
    input:
        chip = lambda w: get_files(w, "ChIP"),
        input = lambda w: get_files(w, "Input"),
    output:
        bed = "{prefix}/data/macs2/{cell}.bed",
    params:
        prefix = "{prefix}/data/macs2/{cell}",
        outfile = "{prefix}/data/macs2/{cell}_peaks.broadPeak"
    conda:
        "envs/macs2.yaml"
    shell:
        "macs2 callpeak --nomodel --extsize 200 --broad -t {input.chip} -c {input.input} -n {params.prefix} && mv {params.outfile} {output[0]}"


rule run_epic_merge:
    input:
        matrixes = expand("{{prefix}}/data/epic/{cell}.matrix.gz",
                          cell=cells),
        bed = expand("{{prefix}}/data/{{caller}}/{cell}.bed",
                     cell=cells)
    output:
        "{prefix}/data/epic-merge/{caller}/matrixes.gz"
    threads:
        24
    shell:
        "epic-merge -cpu {threads} -r {input.bed} -o {output[0]} -m {input.matrixes}"


rule test_epic_merge:
    input:
        matrixes = expand("{{prefix}}/data/epic/{cell}.matrix.gz",
                            cell=cells),
    output:
        "{prefix}/data/epic-merge/test/matrixes.gz"
    threads:
        24
    shell:
        "epic-merge -cpu {threads} -o {output[0]} -m {input.matrixes}"


rule epic_cluster:
    input:
        "{prefix}/data/epic-merge/{caller}/matrixes.gz"
    output:
        matrix = "{prefix}/data/epic-cluster/{caller}/matrixes.gz",
        bed = "{prefix}/data/epic-cluster/{caller}/clusters.bed"
    shell:
        "epic-cluster -m {input[0]} -o {output.matrix} -B {output.bed} -t 1 -cpu 25"
